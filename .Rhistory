vec
### 3b/ Chercher le nombre d'amendements déposés par le député Damien Abad. Créer un objet avec cette information.
### 3c/ Vérifier que le chemin défini fonctionne pour la page de la députée Caroline Abadie
### 3d/ Créer un objet avec les adresses de toutes les pages personnelles des députés
addr <- xpathSApply(y, "//div[@class='list_dep jstitle phototitle block']/span[@class='urlphoto']", xmlGetAttr, "title")
### 3b/ Chercher le nombre d'amendements déposés par le député Damien Abad. Créer un objet avec cette information.
### 3c/ Vérifier que le chemin défini fonctionne pour la page de la députée Caroline Abadie
### 3d/ Créer un objet avec les adresses de toutes les pages personnelles des députés
rm(vec)
addr
req<-request("https://www.nosdeputes.fr/damien-abad")
resp <- req_perform(req)
dam <- resp_body_html(resp)
dam
dam <- htmlParse(dam)
amend<-xpathSApply(dam,"//table[@class='sorts_amendements']/tbody/tr[@class='total_sorts']/td[1]", xmlValue)
amend
amend<-xpathSApply(dam,"//tr[@class='total_sorts']/td[1]", xmlValue)
amend
adresses<-paste()("https://www.nosdeputes.fr", addr)
adresses<-paste0("https://www.nosdeputes.fr", addr)
adresses
job<-xpathSApply(dam,"//div[@class='boite_depute']/ul/li[contains(.,'Profession :')]", xmlValue)
pres<-xpathSApply(dam,"//li[1]/a[@class='jstitle']", xmlValue)
pres
amend
amend<-xpathSApply(dam,"//li[6]/a[@class='jstitle']", xmlValue)
amend
job<-xpathSApply(dam,"//div[@class='boite_depute']/ul/li[contains(.,'Profession :')]", xmlValue)
pres<-xpathSApply(dam,"//li[1]/a[@class='jstitle']", xmlValue)
job<-xpathSApply(dam,"//div[@class='boite_depute']/ul/li[contains(.,'Profession :')]", xmlValue)
job<-xpathSApply(dam,"//div[@id='b1']/ul/li[contains(.,'Profession :')]", xmlValue)
job
job<-xpathSApply(dam,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
job
pres<-xpathSApply(dam,"//li[1]/a[@class='jstitle']", xmlValue)
pres
for i in (1:10) {
pages[i] <- htmlParse(adresses[i])
presences <- c(presence, xpathSApply(pages[i],"//li[1]/a[@class='jstitle']", xmlValue))
amendements <- c(amendements, xpathSApply(pages[i],"//li[6]/a[@class='jstitle']", xmlValue))
profession <- c(profession, xpathSApply(pages[i],"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue))
print(adresses[i])
}
for i in (1:10) {
pages[i] <- htmlParse(adresses[i])
presences <- c(presence, xpathSApply(pages[i],"//li[1]/a[@class='jstitle']", xmlValue))
amendements <- c(amendements, xpathSApply(pages[i],"//li[6]/a[@class='jstitle']", xmlValue))
profession <- c(profession, xpathSApply(pages[i],"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue))
print(adresses[i])
}
for (i in 1:10) {
pages[i] <- htmlParse(adresses[i])
presences <- c(presence, xpathSApply(pages[i],"//li[1]/a[@class='jstitle']", xmlValue))
amendements <- c(amendements, xpathSApply(pages[i],"//li[6]/a[@class='jstitle']", xmlValue))
profession <- c(profession, xpathSApply(pages[i],"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue))
print(adresses[i])
}
for (i in 1:10) {
page <- htmlParse(adresses[i])
presences <- c(presence, xpathSApply(page,"//li[1]/a[@class='jstitle']", xmlValue))
amendements <- c(amendements, xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue))
profession <- c(profession, xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue))
print(adresses[i])
}
for (i in 1:10) {
page <- htmlParse(adresses[i])
presences <- c(presence, xpathSApply(page,"//li[1]/a[@class='jstitle']", xmlValue))
amendements <- c(amendements, xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue))
profession <- c(profession, xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue))
print(adresses[i])
}
for (i in 1:10) {
page <- htmlParse(adresses[i])
presences <- c(presences, xpathSApply(page,"//li[1]/a[@class='jstitle']", xmlValue))
amendements <- c(amendements, xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue))
profession <- c(profession, xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue))
print(adresses[i])
}
deputes$profession<-NA
### 1a/ Pour récupérer le code une page web : la fonction getURL.
#page<-getURL(URL, ssl.verifypeer=F)
req<-request("https://www.nosdeputes.fr/deputes")
resp <- req_perform(req)
resp <- resp_body_html(resp)
resp
### 1b/ Parser la page (fonction "htmlParse")
y <- htmlParse(resp)
### 2// Sélectionner les données
### 2a/ Ecrire l'expression Xpath qui permet d'obtenir le nom de tous les députés
###     Créer un objet "noms" avec le nom de tous les députés
noms<-xpathSApply(y,"//div[@class='list_dep jstitle phototitle block']/span[@class='list_nom']", xmlValue)
### 2b/ Ecrire l'expression Xpath qui permet d'obtenir la circonscription d'origine
###     Créer un objet "circo" avec le nom de toutes les circonscirptions
circo<-xpathSApply(y,"//div[@class='list_dep jstitle phototitle block']/span[@class='list_right'][1]", xmlValue)
### 2c/ Créer une base de données des députés avec trois variables :
###               le nom, le parti et la circonscritpion des députés.
partis<-xpathSApply(y,"//div[@class='list_dep jstitle phototitle block']/span[@class='list_left']/span[1]", xmlValue)
deputes<-cbind(noms,circo,partis)
deputes$profession<-NA
for (i in 1:10) {
page <- htmlParse(adresses[i])
deputes$presences[i] <-  xpathSApply(page,"//li[1]/a[@class='jstitle']", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
print(adresses[i])
}
adresses<-paste0("https://www.nosdeputes.fr", addr)
deputes$profession<-NA
deputes$amendements<-NA
deputes$presences<-NA
for (i in 1:10) {
page <- htmlParse(adresses[i])
deputes$presences[i] <-  xpathSApply(page,"//li[1]/a[@class='jstitle']", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
print(adresses[i])
}
deputes$presences[i] <-  xpathSApply(page,"//li[1]/a[@class='jstitle']", xmlValue)
for (i in 1:10) {
page <- htmlParse(adresses[i])
deputes$presences[i] <-  xpathSApply(page,"//li[1]/a[@class='jstitle']", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
print(adresses[i])
}
deputes
deputes[1]
deputes[1]$circo
deputes$circo[1]
### 2b/ Ecrire l'expression Xpath qui permet d'obtenir la circonscription d'origine
###     Créer un objet "circo" avec le nom de toutes les circonscirptions
circo<-xpathSApply(y,"//div[@class='list_dep jstitle phototitle block']/span[@class='list_right'][1]", xmlValue)
### 2c/ Créer une base de données des députés avec trois variables :
###               le nom, le parti et la circonscritpion des députés.
partis<-xpathSApply(y,"//div[@class='list_dep jstitle phototitle block']/span[@class='list_left']/span[1]", xmlValue)
deputes<-cbind(noms,circo,partis)
deputes[1]
View(deputes)
deputes$circo[1]
deputes$circo[1]
deputes$circo
deputes[1]
deputes[1]$circo
deputes<-cbind(noms,circo,partis)
View(deputes)
deputes$noms
deputes[1].noms
deputes[1]$noms
deputes["noms"]
deputes["noms"][1]
deputes[1]["noms"]
deputes[1]
deputes[1]["circo"]
deputes[1][circo]
View(deputes)
deputes <- as.list(deputes)
deputes$noms
deputes$noms[1]
deputes[1]
deputes[1]["circo"]
deputes[1]$circo
deputes<-cbind(noms,circo,partis)
View(deputes)
for (i in 1:10) {
page <- htmlParse(adresses[i])
deputes$presences[i] <-  xpathSApply(page,"//li[1]/a[@class='jstitle']", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
print(adresses[i])
}
deputes <- as.data.frame(deputes)
deputes$profession<-NA
deputes$amendements<-NA
deputes$presences<-NA
for (i in 1:10) {
page <- htmlParse(adresses[i])
deputes$presences[i] <-  xpathSApply(page,"//li[1]/a[@class='jstitle']", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
print(adresses[i])
}
deputes$presences[i] <-  xpathSApply(page,"//li[1]/a[@class='jstitle']", xmlValue)
deputes$circo[1]
deputes$profession<-NA
deputes$amendements<-NA
deputes$presences<-NA
for (i in 1:10) {
page <- htmlParse(adresses[i])
deputes$presences[i] <-  xpathSApply(page,"//li[1]/a[@class='jstitle']", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
print(adresses[i])
}
deputes$presences[i] <-  xpathSApply(page,"//li[1]/a[@class='jstitle']//text()", xmlValue)
for (i in 1:10) {
page <- htmlParse(adresses[i])
deputes$presences[i] <-  xpathSApply(page,"//li[1]/a[@class='jstitle']//text()", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
print(adresses[i])
}
deputes$presences[1]
deputes$presences[1] <- 0
for (i in 1:10) {
page <- htmlParse(adresses[i])
deputes$presences[i] <-  xpathSApply(page,"//li[1]/a[@class='jstitle']//text()", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
print(adresses[i])
}
page
deputes$presences[i] <-  xpathSApply(page,"//li[1]/a[@class='jstitle']//text()", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
for (i in 1:10) {
page <- htmlParse(adresses[i])
deputes$presences[i] <-  xpathSApply(page,"//li[1]/a[@class='jstitle']//text()", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
print(adresses[i])
}
amend<-xpathSApply(dam,"//li[6]/a[@class='jstitle']", xmlValue)
amend
pres<-xpathSApply(dam,"//li[1]/a[@class='jstitle']", xmlValue)
pres
for (i in 1:10) {
page <- htmlParse(adresses[i])
deputes$presences[i] <-  xpathSApply(page,"//li[1]/a[@class='jstitle']//text()", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
print(adresses[i])
}
deputes$presences[i] <- NA
deputes$presences[i] <-  xpathSApply(page,"//li[1]/a[@class='jstitle']//text()", xmlValue)
for (i in 1:10) {
page <- htmlParse(adresses[i])
deputes$presences[i] <-  xpathSApply(page,"//li[1]/a[@class='jstitle']//text()", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
print(adresses[i])
}
for (i in 1:10) {
req<-request(adresses[i])
resp <- req_perform(req)
dep <- resp_body_html(resp)
page <- htmlParse(dep)
deputes$presences[i] <-  xpathSApply(page,"//li[1]/a[@class='jstitle']//text()", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
print(adresses[i])
}
View(deputes)
for (i in 1:577) {
req<-request(adresses[i])
resp <- req_perform(req)
dep <- resp_body_html(resp)
page <- htmlParse(dep)
deputes$presences[i] <-  xpathSApply(page,"//li[1]/a[@class='jstitle']//text()", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
print(adresses[i])
}
View(deputes)
pres<-xpathSApply(dam, "//img[contains(@alt, "Semaines")]", xmlValue)
pres<-xpathSApply(dam, "//img[contains(@alt, 'Semaines)]", xmlValue)
pres<-xpathSApply(dam, "//img[contains(@alt, 'Semaines')]", xmlValue)
pres
pres<-xpathSApply(dam,"//li[1]/a[@class='jstitle']", xmlValue)
pres<-xpathSApply(dam, "//span[contains(@title, 'activité')]/text()", xmlValue)
pres
req<-request("https://www.nosdeputes.fr/damien-abad")
resp <- req_perform(req)
dam <- resp_body_html(resp)
dam
dam <- htmlParse(dam)
job<-xpathSApply(dam,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
job
pres<-xpathSApply(dam,"//li[1]/a[@class='jstitle']", xmlValue)
pres<-xpathSApply(dam, "//span[contains(@title, 'activité')]/text()", xmlValue)
pres
pres<-xpathSApply(dam, "//span[contains(@title, 'activité')]/text()", xmlValue)
pres
pres<-xpathSApply(dam, "//span[contains(@title, 'activité')]/text()|//li[1]/a[@class='jstitle']", xmlValue)
pres
for (i in 1:577) {
req<-request(adresses[i])
resp <- req_perform(req)
dep <- resp_body_html(resp)
page <- htmlParse(dep)
deputes$presences[i] <-  xpathSApply(page,"//span[contains(@title, 'activité')]/text()|//li[1]/a[@class='jstitle']", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
print(adresses[i])
}
deputes$presences[i] <-  xpathSApply(page,"//span[contains(@title, 'activité')]|//li[1]/a[@class='jstitle']", xmlValue)
for (i in 1:577) {
req<-request(adresses[i])
resp <- req_perform(req)
dep <- resp_body_html(resp)
page <- htmlParse(dep)
deputes$presences[i] <-  xpathSApply(page,"//span[contains(@title, 'activité')]|//li[1]/a[@class='jstitle']", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
print(adresses[i])
}
pres<-xpathSApply(dam, "//span[contains(@title, 'activité')]|//li[1]/a[@class='jstitle']", xmlValue)
pres
for (i in 1:577) {
req<-request(adresses[i])
resp <- req_perform(req)
dep <- resp_body_html(resp)
page <- htmlParse(dep)
deputes$presences[i] <-  xpathSApply(page,"//span[contains(@title, 'activité')]|//li[1]/a[@class='jstitle']", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
print(adresses[i])
}
for (i in 1:577) {
req<-request(adresses[i])
resp <- req_perform(req)
dep <- resp_body_html(resp)
page <- htmlParse(dep)
deputes$presences[i] <-  xpathSApply(page,"//span[contains(@title, 'activité')]/text()|//li[1]/a[@class='jstitle']", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
print(adresses[i])
}
pres<-xpathSApply(dam, "//span[contains(@title, 'activité')]/text()", xmlValue)
pres
pres<-xpathSApply(dam,"//li[1]/a[@class='jstitle']", xmlValue)
pres
pres<-xpathSApply(dam,"//li[1]/a[@class='jstitle']/text()", xmlValue)
pres
for (i in 1:577) {
print(adresses[i])
req<-request(adresses[i])
resp <- req_perform(req)
dep <- resp_body_html(resp)
page <- htmlParse(dep)
deputes$presences[i] <-  xpathSApply(page,"//span[contains(@title, 'activité')]/text()|//li[1]/a[@class='jstitle']", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
}
for (i in 1:577) {
print(adresses[i])
req<-request(adresses[i])
resp <- req_perform(req)
dep <- resp_body_html(resp)
page <- htmlParse(dep)
deputes$presences[i] <-  xpathSApply(page,"//div[@class='graph_depute']/p//span[@class='jstitle'][1]|//li[1]/a[@class='jstitle']", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
}
for (i in 1:577) {
print(adresses[i])
req<-request(adresses[i])
resp <- req_perform(req)
dep <- resp_body_html(resp)
page <- htmlParse(dep)
deputes$presences[i] <-  xpathSApply(page,"//div[@class='graph_depute']/p//span[@class='jstitle'][1]|//li[1]/a[@class='jstitle']", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//div[@class='barre_activite']/ul/li[6]/span[@class='jstitle']|//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
}
View(deputes)
for (i in 1:577) {
print(adresses[i])
req<-request(adresses[i])
resp <- req_perform(req)
dep <- resp_body_html(resp)
page <- htmlParse(dep)
deputes$presences[i] <-  xpathSApply(page,"///div[@class='barre_activite']/ul//span[@class='jstitle'][1]|//li[1]/a[@class='jstitle']", xmlValue)
deputes$amendements[i] <- xpathSApply(page,"//div[@class='barre_activite']/ul/li[6]/span[@class='jstitle']|//li[6]/a[@class='jstitle']", xmlValue)
deputes$profession[i] <- xpathSApply(page,"//div[@id='b1']/ul/li[contains(.,'Profession')]", xmlValue)
}
View(deputes)
install.packages(c("RCurl","XML" ))
library(RCurl)### récupérer des pages URL
library(XML) ### parser : parcourir un texte Html pour en extraire des éléments
install.packages(c("RCurl", "XML"))
install.packages(c("RCurl", "XML"))
install.packages(c("RCurl","XML" ))
library(RCurl)### récupérer des pages URL
library(XML) ### parser : parcourir un texte Html pour en extraire des éléments
library(httr2)
req<-request("https://www.allocine.fr/films/decennie-2010/annee-2017/")
resp <- req_perform(req)
resp <- resp_body_html(resp)
resp
page <- htmlParse(resp)
titles <- xpathSApply(page, "//a[@class='meta-title-link']/text()", xmlValue)
titles
real <- xpathSApply(page, "//div[@class='meta-body-item meta-body-direction']/a[1]", xmlValue)
real
real
titles <- xpathSApply(page, "//a[@class='meta-title-link']/text()", xmlValue)
titles
real <- xpathSApply(page, "//div[@class='meta-body-item meta-body-direction']/a[1]", xmlValue)
real
real <- xpathSApply(page, "//div[@class='meta-body-item meta-body-direction']/a[1]/text()", xmlValue)
real
real <- xpathSApply(page, "//div[@class='meta-body-item meta-body-direction']/a[1]/text()", xmlValue)
real
resp
page <- htmlParse(resp)
titles <- xpathSApply(page, "//a[@class='meta-title-link']/text()", xmlValue)
titles
real <- xpathSApply(page, "//div[@class='meta-body-item meta-body-direction']/a[1]/text()", xmlValue)
real
real <- xpathSApply(page, "//div[@class='meta-body-item meta-body-direction']/a[1]/text()", xmlValue)
real
req<-request("https://www.allocine.fr/films/decennie-2010/annee-2017/")
resp <- req_perform(req)
resp <- resp_body_html(resp)
resp
page <- htmlParse(resp)
titles <- xpathSApply(page, "//a[@class='meta-title-link']/text()", xmlValue)
titles
real <- xpathSApply(page, "//div[@class='meta-body-item meta-body-direction']/a[1]", xmlValue)
real
View(real)
real <- xpathSApply(page, "//div[@class='meta-body-item meta-body-direction']/a[1]/text()", xmlValue)
View(real)
real
eval <- xpathSApply(page, "//div[@class='rating-item'][1]/div/div/span[@class='stareval-note']", xmlValue)
eval
evalViewers <- xpathSApply(page, "//div[@class='rating-item'][2]/div/div/span[@class='stareval-note']", xmlValue)
evalViewers
real <- xpathSApply(page, "//a[@class='xXx blue-link']")
real
real <- xpathSApply(page, "//a[@class='xXx blue-link']", xmlValue)
real
real <- xpathSApply(page, "//div[@class='meta-body-item meta-body-direction']", xmlValue)
real
real
evalViewers <- xpathSApply(page, "//div[@class='rating-item'][2]/div/div/span[@class='stareval-note']", xmlValue)
real <- xpathSApply(page, "//div[@class='meta-body-item meta-body-direction']", xmlValue)
real
View(real)
real <- xpathSApply(page, "//div[@class='meta-body-item meta-body-direction']", xmlValue)
eval
####Obtenir toutes les addresses :
adresses<-paste0("https://www.allocine.fr/films/decennie-2010/annee-2017/", 1:173)
adresses
install.packages(c("RCurl","XML" ))
library(RCurl)### récupérer des pages URL
library(XML) ### parser : parcourir un texte Html pour en extraire des éléments
library(httr2)
req<-request("https://www.allocine.fr/films/decennie-2010/annee-2017/")
resp <- req_perform(req)
resp <- resp_body_html(resp)
resp
install.packages(c("RCurl","XML" ))
library(RCurl)### récupérer des pages URL
library(XML) ### parser : parcourir un texte Html pour en extraire des éléments
library(httr2)
req<-request("https://twitter.com/search?q=chatgpt%20lang%3Afr%20-filter%3Alinks%20-filter%3Areplies&src=typed_query&f=top")
resp <- req_perform(req)
resp <- resp_body_html(resp)
resp
install.packages(c("RCurl", "XML"))
req<-request("https://twitter.com/search?q=chatgpt%20lang%3Afr%20-filter%3Alinks%20-filter%3Areplies&src=typed_query&f=top")
resp <- req_perform(req)
resp <- resp_body_html(resp)
resp
resp
resp <- resp_body_html(resp)
resp
page <- htmlParse(resp)
library(RCurl)### récupérer des pages URL
library(XML) ### parser : parcourir un texte Html pour en extraire des éléments
library(httr2)
req<-request("https://twitter.com/search?q=chatgpt%20lang%3Afr%20-filter%3Alinks%20-filter%3Areplies&src=typed_query&f=top")
resp <- req_perform(req)
resp <- resp_body_html(resp)
resp
page
page
page <- htmlParse(resp)
resp <- resp_body_html(resp)
resp
page <- htmlParse(resp)
evalViewers <- xpathSApply(page, "//div[@class='css-901oao css-16my406 r-poiln3 r-bcqeeo r-qvutc0']", xmlValue)
evalViewers
rm(list=ls())
install.packages(c("tidyr", "stringr", "dplyr", "quanteda",
"quanteda.textstats", "ggplot2", "wordcloud",
"wordcloud2", "RColorBrewer","topicmodels","LDAvis"))
library(tidyr)
library(stringr)
library(dplyr)
library(quanteda)
library(quanteda.textstats)
library(ggplot2)
library(wordcloud)
library(wordcloud2)
library(RColorBrewer)
setwd("C:/Users/isama/OneDrive/Documents/UTC/GI05/IC05")
base<-read.csv2("2023tweet.csv",header=T, sep=",")
summary(base)
#Suppression des doublons
a<-as.vector(which(duplicated(base$Tweet.body)==T))
base<-base[-a,]
#Suppression des dates des pubs (1970)
base$Date<-as.Date(base$Date, "%Y-%m-%d")
base <- subset(base, format(base$Date, "%Y") != "1970")
#Graphique Tweet en fonction de la date
ggplot(base, aes(x=Date, y=..count..))+
geom_bar()+
theme_classic()+
scale_x_date(date_breaks = "1 week", date_labels =  "%b %d")+
theme(axis.text.x = element_text(angle=90, vjust = 0.5))
install.packages(c("tidyr", "stringr", "dplyr", "quanteda", "quanteda.textstats", "ggplot2", "wordcloud", "wordcloud2", "RColorBrewer", "topicmodels", "LDAvis"))
